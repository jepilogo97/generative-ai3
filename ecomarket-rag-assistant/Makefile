# =========================
# EcoMarket RAG ‚Äì Makefile
# =========================

# ---- Config ----
APP_NAME       ?= pedidos-app
SERVICE        ?= pedidos-app
OLLAMA_NAME    ?= ollama
STREAMLIT_PORT ?= 8501
OLLAMA_PORT    ?= 11434
MODEL_NAME     ?= llama3
PY             ?= python
COMPOSE        := docker compose

# ---- Ayuda ----
.PHONY: help
help:
	@echo ""
	@echo "Comandos disponibles:"
	@echo ""
	@echo "üöÄ Inicio r√°pido:"
	@echo "  make first-run    - Primera instalaci√≥n completa (build + up + modelo + ingest)"
	@echo ""
	@echo "üì¶ Operaciones b√°sicas:"
	@echo "  make build        - Construye las im√°genes Docker"
	@echo "  make up           - Levanta todos los contenedores en segundo plano"
	@echo "  make down         - Detiene y elimina los contenedores"
	@echo "  make restart      - Reinicia los contenedores"
	@echo "  make status       - Muestra estado de los contenedores"
	@echo ""
	@echo "üìä Logs:"
	@echo "  make logs         - Logs de todos los servicios"
	@echo "  make logs-app     - Logs solo de la app"
	@echo "  make logs-ollama  - Logs solo de Ollama"
	@echo ""
	@echo "ü§ñ Ollama:"
	@echo "  make setup-ollama - Configura Ollama completamente (espera + descarga + verifica)"
	@echo "  make check-ollama - Lista modelos instalados"
	@echo "  make pull-model   - Descarga el modelo LLM (usa MODEL_NAME)"
	@echo "  make verify-model - Verifica que el modelo exista"
	@echo "  make wait-ollama  - Espera a que Ollama est√© listo"
	@echo "  make ollama-shell - Shell dentro del contenedor Ollama"
	@echo ""
	@echo "üìä Data & RAG:"
	@echo "  make ingest       - Ejecuta ingesta de datos (crea √≠ndice FAISS)"
	@echo "  make clean        - Limpia artifacts locales"
	@echo "  make clean-all    - Limpieza profunda (incluye vol√∫menes)"
	@echo ""
	@echo "üîß Utilidades:"
	@echo "  make check        - Verifica Docker/Compose"
	@echo "  make shell        - Shell dentro del contenedor de la app"
	@echo "  make test-agent   - Ejecuta pruebas del agente"
	@echo ""
	@echo "üí° Ejemplos:"
	@echo "  make first-run                      - Instalaci√≥n completa con modelo por defecto"
	@echo "  make first-run MODEL_NAME=llama3.1  - Instalaci√≥n con modelo espec√≠fico"
	@echo "  make pull-model MODEL_NAME=mistral  - Descargar modelo alternativo"
	@echo ""

# ---- Checks ----
.PHONY: check
check:
	@docker --version >/dev/null 2>&1 || (echo "‚ùå Docker no disponible"; exit 1)
	@$(COMPOSE) version >/dev/null 2>&1 || (echo "‚ùå Docker Compose no disponible"; exit 1)
	@$(PY) --version
	@echo "‚úÖ Entorno OK"

# ---- Build/Run ----
.PHONY: build
build:
	@echo "üî® Construyendo im√°genes..."
	$(COMPOSE) build --no-cache
	@echo "‚úÖ Build completado"

.PHONY: up
up:
	@echo "üöÄ Levantando servicios..."
	$(COMPOSE) up -d
	@echo ""
	@echo "‚úÖ Servicios iniciados:"
	@echo "   ‚Ä¢ Streamlit:  http://localhost:$(STREAMLIT_PORT)"
	@echo "   ‚Ä¢ Ollama:     http://localhost:$(OLLAMA_PORT)"
	@echo ""
	@echo "üí° Usa 'make logs' para ver logs en vivo"
	@echo "üí° Usa 'make check-ollama' para verificar modelos"

.PHONY: down
down:
	@echo "üõë Deteniendo servicios..."
	$(COMPOSE) down
	@echo "‚úÖ Servicios detenidos"

.PHONY: restart
restart: down up

.PHONY: status
status:
	@echo "üìä Estado de los contenedores:"
	@$(COMPOSE) ps

# ---- Logs ----
.PHONY: logs
logs:
	$(COMPOSE) logs -f

.PHONY: logs-app
logs-app:
	$(COMPOSE) logs -f $(SERVICE)

.PHONY: logs-ollama
logs-ollama:
	$(COMPOSE) logs -f $(OLLAMA_NAME)

# ---- Ollama (versi√≥n corregida y robusta) ----
.PHONY: wait-ollama
wait-ollama:
	@echo "‚è≥ Esperando a que Ollama est√© listo..."
	@for i in 1 2 3 4 5 6 7 8 9 10 11 12; do \
		if docker exec $(OLLAMA_NAME) curl -s http://localhost:11434/api/tags >/dev/null 2>&1; then \
			echo "‚úÖ Ollama est√° listo (intento $$i/12)"; \
			exit 0; \
		fi; \
		echo "   ‚è≥ Intento $$i/12... esperando 5 segundos"; \
		sleep 5; \
	done; \
	echo "‚ùå ERROR: Ollama no respondi√≥ despu√©s de 60 segundos"; \
	echo "üí° Verifica logs con: make logs-ollama"; \
	exit 1

.PHONY: pull-model
pull-model:
	@echo "üì• Descargando modelo $(MODEL_NAME)..."
	@echo "‚è≥ Esto puede tardar varios minutos dependiendo del tama√±o y tu conexi√≥n..."
	@echo ""
	docker exec $(OLLAMA_NAME) ollama pull $(MODEL_NAME) || \
		(echo ""; \
		 echo "‚ùå ERROR: No se pudo descargar el modelo $(MODEL_NAME)"; \
		 echo ""; \
		 echo "üí° Posibles soluciones:"; \
		 echo "   1. Verifica que el nombre del modelo sea correcto"; \
		 echo "   2. Modelos disponibles comunes:"; \
		 echo "      - llama3 (recomendado)"; \
		 echo "      - llama3.1"; \
		 echo "      - llama3.2"; \
		 echo "      - llama2"; \
		 echo "      - mistral"; \
		 echo "      - phi3"; \
		 echo "   3. Prueba con otro modelo:"; \
		 echo "      make pull-model MODEL_NAME=llama3"; \
		 echo "   4. Busca m√°s modelos en: https://ollama.ai/library"; \
		 echo ""; \
		 exit 1)
	@echo ""
	@echo "‚úÖ Modelo $(MODEL_NAME) descargado exitosamente"

.PHONY: verify-model
verify-model:
	@echo "üîç Verificando modelo $(MODEL_NAME)..."
	@if docker exec $(OLLAMA_NAME) ollama list 2>/dev/null | grep -q "$(MODEL_NAME)"; then \
		echo "‚úÖ Modelo $(MODEL_NAME) confirmado y listo para usar"; \
	else \
		echo "‚ùå ERROR: Modelo $(MODEL_NAME) no encontrado despu√©s de la descarga"; \
		echo "üí° Verifica modelos instalados con: make check-ollama"; \
		exit 1; \
	fi

.PHONY: setup-ollama
setup-ollama: wait-ollama pull-model verify-model
	@echo ""
	@echo "‚úÖ Ollama configurado completamente"
	@echo ""
	@$(MAKE) check-ollama

.PHONY: check-ollama
check-ollama:
	@echo "üîç Modelos instalados en Ollama:"
	@docker exec $(OLLAMA_NAME) ollama list 2>/dev/null || \
		(echo "‚ùå Ollama no est√° corriendo"; \
		 echo "üí° Ejecuta: make up"; \
		 exit 1)

.PHONY: ollama-shell
ollama-shell:
	@echo "üêö Abriendo shell en contenedor Ollama..."
	@docker exec -it $(OLLAMA_NAME) /bin/bash

# ---- Data / RAG ----
.PHONY: ingest
ingest:
	@echo "üì¶ Ejecutando ingesta de datos (generando √≠ndice FAISS)..."
	@echo "‚è≥ Esto puede tardar 1-2 minutos..."
	$(COMPOSE) exec $(SERVICE) python src/ingest_data.py
	@echo "‚úÖ √çndice FAISS actualizado correctamente"

# ---- Shell ----
.PHONY: shell
shell:
	@echo "üêö Abriendo shell en contenedor de la app..."
	$(COMPOSE) exec $(SERVICE) bash

# ---- Limpieza ----
.PHONY: clean
clean:
	@echo "üßπ Limpiando artifacts locales..."
	@rm -rf artifacts/faiss_index/* artifacts/meta.jsonl 2>/dev/null || true
	@echo "‚úÖ Limpieza completada"

.PHONY: clean-all
clean-all: down clean
	@echo "üßπ Limpieza profunda (incluye vol√∫menes de Docker)..."
	$(COMPOSE) down -v
	@echo "‚ö†Ô∏è  Se eliminaron:"
	@echo "   - Contenedores"
	@echo "   - Vol√∫menes (modelos de Ollama descargados)"
	@echo "   - Artifacts locales"
	@echo ""
	@echo "‚úÖ Limpieza profunda completada"
	@echo "üí° Para volver a empezar: make first-run"

# ---- Primera ejecuci√≥n completa ----
.PHONY: first-run
first-run: check build up setup-ollama ingest
	@echo ""
	@echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
	@echo "üéâ ¬°Configuraci√≥n inicial completada exitosamente!"
	@echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
	@echo ""
	@echo "üìä Recursos disponibles:"
	@echo "   ‚Ä¢ Streamlit:  http://localhost:$(STREAMLIT_PORT)"
	@echo "   ‚Ä¢ Ollama:     http://localhost:$(OLLAMA_PORT)"
	@echo "   ‚Ä¢ Modelo:     $(MODEL_NAME)"
	@echo ""
	@echo "üöÄ Pr√≥ximos pasos:"
	@echo "   1. Abre tu navegador en: http://localhost:$(STREAMLIT_PORT)"
	@echo "   2. Prueba el agente con: make test-agent"
	@echo "   3. Ve logs en tiempo real: make logs"
	@echo ""
	@echo "üí° Comandos √∫tiles:"
	@echo "   - make status        Ver estado de contenedores"
	@echo "   - make check-ollama  Verificar modelos instalados"
	@echo "   - make restart       Reiniciar servicios"
	@echo "   - make help          Ver todos los comandos"
	@echo ""
	@echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"

# ---- Pruebas del Agente ----
.PHONY: test-agent
test-agent:
	@echo "üß™ Ejecutando suite de pruebas del agente..."
	@echo "‚è≥ Esto puede tardar 1-2 minutos..."
	@echo ""
	$(COMPOSE) exec $(SERVICE) python test_agent.py

.PHONY: test-agent-local
test-agent-local:
	@echo "üß™ Ejecutando pruebas del agente localmente..."
	$(PY) test_agent.py

# ---- Comandos de desarrollo ----
.PHONY: dev-restart
dev-restart:
	@echo "üîÑ Reinicio r√°pido para desarrollo..."
	$(COMPOSE) restart $(SERVICE)
	@echo "‚úÖ Aplicaci√≥n reiniciada"

.PHONY: dev-logs
dev-logs:
	@echo "üìã Siguiendo logs de la aplicaci√≥n..."
	$(COMPOSE) logs -f --tail=100 $(SERVICE)

# ---- Diagn√≥stico ----
.PHONY: diagnose
diagnose:
	@echo "üîç Diagn√≥stico del sistema:"
	@echo ""
	@echo "=== Docker ==="
	@docker --version || echo "‚ùå Docker no disponible"
	@echo ""
	@echo "=== Docker Compose ==="
	@$(COMPOSE) version || echo "‚ùå Docker Compose no disponible"
	@echo ""
	@echo "=== Contenedores ==="
	@docker ps --filter name=$(OLLAMA_NAME) --filter name=$(SERVICE)
	@echo ""
	@echo "=== Modelos Ollama ==="
	@docker exec $(OLLAMA_NAME) ollama list 2>/dev/null || echo "‚ùå Ollama no est√° corriendo"
	@echo ""
	@echo "=== √çndice FAISS ==="
	@if [ -f "artifacts/faiss_index/index.faiss" ]; then \
		echo "‚úÖ √çndice FAISS existe"; \
	else \
		echo "‚ùå √çndice FAISS no encontrado"; \
	fi
	@echo ""
	@echo "=== Base de datos ==="
	@if [ -f "data/ecomarket_chat.db" ]; then \
		echo "‚úÖ Base de datos existe"; \
	else \
		echo "‚ùå Base de datos no encontrada"; \
	fi
# =========================
# EcoMarket RAG â€“ Makefile
# =========================

# ---- Config ----
APP_NAME       ?= pedidos-app
SERVICE        ?= pedidos-app
OLLAMA_NAME    ?= ollama
STREAMLIT_PORT ?= 8501
OLLAMA_PORT    ?= 11434
MODEL_NAME     ?= llama3.2:3b
PY             ?= python
COMPOSE        := docker compose

# ---- Ayuda ----
.PHONY: help
help:
	@echo ""
	@echo "Comandos disponibles:"
	@echo ""
	@echo "ğŸš€ Inicio rÃ¡pido:"
	@echo "  make first-run    - Primera instalaciÃ³n completa (build + up + modelo + ingest)"
	@echo ""
	@echo "ğŸ“¦ Operaciones bÃ¡sicas:"
	@echo "  make build        - Construye las imÃ¡genes Docker"
	@echo "  make up           - Levanta todos los contenedores en segundo plano"
	@echo "  make down         - Detiene y elimina los contenedores"
	@echo "  make restart      - Reinicia los contenedores"
	@echo "  make status       - Muestra estado de los contenedores"
	@echo ""
	@echo "ğŸ“Š Logs:"
	@echo "  make logs         - Logs de todos los servicios"
	@echo "  make logs-app     - Logs solo de la app"
	@echo "  make logs-ollama  - Logs solo de Ollama"
	@echo ""
	@echo "ğŸ¤– Ollama:"
	@echo "  make setup-ollama - Descarga el modelo LLM en Ollama"
	@echo "  make check-ollama - Lista modelos instalados"
	@echo "  make ollama-shell - Shell dentro del contenedor Ollama"
	@echo ""
	@echo "ğŸ“Š Data & RAG:"
	@echo "  make ingest       - Ejecuta ingesta de datos (crea Ã­ndice FAISS)"
	@echo "  make clean        - Limpia artifacts locales"
	@echo "  make clean-all    - Limpieza profunda (incluye volÃºmenes)"
	@echo ""
	@echo "ğŸ”§ Utilidades:"
	@echo "  make check        - Verifica Docker/Compose"
	@echo "  make shell        - Shell dentro del contenedor de la app"
	@echo ""

# ---- Checks ----
.PHONY: check
check:
	@docker --version >/dev/null 2>&1 || (echo "âŒ Docker no disponible"; exit 1)
	@$(COMPOSE) version >/dev/null 2>&1 || (echo "âŒ Docker Compose no disponible"; exit 1)
	@$(PY) --version
	@echo "âœ… Entorno OK"

# ---- Build/Run ----
.PHONY: build
build:
	@echo "ğŸ”¨ Construyendo imÃ¡genes..."
	$(COMPOSE) build --no-cache
	@echo "âœ… Build completado"

.PHONY: up
up:
	@echo "ğŸš€ Levantando servicios..."
	$(COMPOSE) up -d
	@echo ""
	@echo "âœ… Servicios iniciados:"
	@echo "   â€¢ Streamlit:  http://localhost:$(STREAMLIT_PORT)"
	@echo "   â€¢ Ollama:     http://localhost:$(OLLAMA_PORT)"
	@echo ""
	@echo "ğŸ’¡ Usa 'make logs' para ver logs en vivo"
	@echo "ğŸ’¡ Usa 'make check-ollama' para verificar el modelo"

.PHONY: down
down:
	@echo "ğŸ›‘ Deteniendo servicios..."
	$(COMPOSE) down
	@echo "âœ… Servicios detenidos"

.PHONY: restart
restart: down up

.PHONY: status
status:
	@echo "ğŸ“Š Estado de los contenedores:"
	@$(COMPOSE) ps

# ---- Logs ----
.PHONY: logs
logs:
	$(COMPOSE) logs -f

.PHONY: logs-app
logs-app:
	$(COMPOSE) logs -f $(SERVICE)

.PHONY: logs-ollama
logs-ollama:
	$(COMPOSE) logs -f $(OLLAMA_NAME)

# ---- Ollama ----
.PHONY: setup-ollama
setup-ollama:
	@echo "ğŸ“¦ Descargando modelo $(MODEL_NAME) en Ollama..."
	-@docker exec $(OLLAMA_NAME) ollama pull $(MODEL_NAME)
	@echo "âœ… Modelo $(MODEL_NAME) preparado"
	@$(MAKE) check-ollama

.PHONY: check-ollama
check-ollama:
	@echo "ğŸ” Modelos instalados en Ollama:"
	-@docker exec $(OLLAMA_NAME) ollama list || echo "âŒ Ollama no estÃ¡ corriendo"

.PHONY: ollama-shell
ollama-shell:
	@echo "ğŸš Shell en contenedor Ollama..."
	@docker exec -it $(OLLAMA_NAME) /bin/bash

# ---- Espera Ollama (versiÃ³n portable)
.PHONY: wait-ollama
wait-ollama:
	@echo "â³ Verificando si Ollama responde..."
	-@docker exec $(OLLAMA_NAME) curl -s http://localhost:11434/api/tags > NUL 2>&1 || echo "âš ï¸ Ollama puede no estar listo todavÃ­a"
	@echo "âœ… Continuando..."

# ---- Data / RAG ----
.PHONY: ingest
ingest:
	@echo "ğŸ“¦ Ejecutando ingesta de datos (FAISS)..."
	$(COMPOSE) exec $(SERVICE) python src/ingest_data.py
	@echo "âœ… Ãndice FAISS actualizado"

# ---- Shell ----
.PHONY: shell
shell:
	@echo "ğŸš Shell en contenedor de la app..."
	$(COMPOSE) exec $(SERVICE) bash

# ---- Limpieza ----
.PHONY: clean
clean:
	@echo "ğŸ§¹ Limpiando artifacts/..."
	@rm -rf artifacts/faiss_index/* artifacts/meta.jsonl 2>/dev/null || true
	@echo "âœ… Limpieza completada"

.PHONY: clean-all
clean-all: down clean
	@echo "ğŸ§¹ Limpieza profunda (incluye volÃºmenes de Ollama)..."
	$(COMPOSE) down -v
	@echo "âš ï¸  Se eliminaron modelos descargados"
	@echo "âœ… Limpieza profunda completada"

# ---- Primera ejecuciÃ³n completa ----
.PHONY: first-run
first-run: check build up wait-ollama setup-ollama ingest
	@echo ""
	@echo "ğŸ‰ Â¡ConfiguraciÃ³n inicial completa!"
	@echo "   â€¢ Streamlit:  http://localhost:$(STREAMLIT_PORT)"
	@echo "   â€¢ Ollama:     http://localhost:$(OLLAMA_PORT)"
	@echo "ğŸš€ Tu aplicaciÃ³n estÃ¡ lista"

# ---- Pruebas del Agente ----
.PHONY: test-agent
test-agent:
	@echo "ğŸ§ª Ejecutando pruebas del agente en contenedor..."
	$(COMPOSE) exec $(SERVICE) python test_agent.py

.PHONY: test-agent-local
test-agent-local:
	@echo "ğŸ§ª Ejecutando pruebas del agente localmente..."
	$(PY) test_agent.py
